import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from collections import Counter
# Load data
data = load_breast_cancer()
X, y = data.data, data.target
features, targets = data.feature_names, data.target_names
# Entropy calculation
def entropy(labels):
    total = len(labels)
    counts = Counter(labels)
    return -sum((c/total) * np.log2(c/total) for c in counts.values())
dataset_entropy = entropy(y)
print(f"Entropy of the dataset: {dataset_entropy:.4f}")
# Information Gain for each feature
for i, name in enumerate(features):
    values = X[:, i]
    median = np.median(values)
    left, right = y[values <= median], y[values > median]
    weighted_entropy = (len(left)*entropy(left) + len(right)*entropy(right)) / len(y)
    info_gain = dataset_entropy - weighted_entropy
    print(f"Information Gain for {name}: {info_gain:.4f}")
# Train and visualize Decision Tree
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=42)
model.fit(X_train, y_train)
plt.figure(figsize=(15, 10))
plot_tree(model, feature_names=features, class_names=targets, filled=True, rounded=True)
plt.title("Decision Tree Visualization")
plt.show()
new_sample = np.array([[17.99, 10.38, 122.8, 1001.0, 0.1184,0.2776, 0.3001, 0.1471, 0.2419, 0.07871,1.095, 0.9053, 8.589, 153.4, 0.006399,0.04904, 0.05373, 0.01587, 0.03003, 0.006193,25.38, 17.33, 184.6, 2019.0, 0.1622,0.6656, 0.7119, 0.2654, 0.4601, 0.1189]])
prediction = model.predict(new_sample)
print(f"Prediction by the model:{target_names[prediction[0]]}")
